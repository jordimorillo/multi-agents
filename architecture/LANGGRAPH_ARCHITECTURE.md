# Arquitectura Multi-Agente con LangChain + LangGraph

## ğŸ¯ Por quÃ© LangChain + LangGraph

### LangChain
- **AbstracciÃ³n de LLMs**: Soporte unificado para OpenAI, Anthropic, etc.
- **Chains y Tools**: ComposiciÃ³n modular de funcionalidades
- **Memory**: GestiÃ³n de contexto y historial
- **Callbacks**: Tracking de tokens, costos, latencia

### LangGraph
- **State Management**: Estado compartido entre agentes
- **Graph-based Workflows**: Define flujos complejos con dependencias
- **Conditional Edges**: Routing inteligente entre agentes
- **Checkpointing**: Persistencia de estado para recuperaciÃ³n
- **Human-in-the-loop**: Aprobaciones y feedback

## ğŸ—ï¸ Arquitectura Revisada con LangGraph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LANGGRAPH ORCHESTRATOR                     â”‚
â”‚  - Define el grafo de agentes y dependencias           â”‚
â”‚  - Gestiona estado compartido                          â”‚
â”‚  - Coordina flujo entre agentes                        â”‚
â”‚  - Checkpoints para recuperaciÃ³n                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   SHARED STATE GRAPH       â”‚
        â”‚  - Task context            â”‚
        â”‚  - Linear issues           â”‚
        â”‚  - GitHub branches         â”‚
        â”‚  - Dependencies resolved   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚
        â†“                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT NODE   â”‚         â”‚ AGENT NODE   â”‚
â”‚  - LangChain â”‚         â”‚  - LangChain â”‚
â”‚  - Tools     â”‚         â”‚  - Tools     â”‚
â”‚  - RAG       â”‚         â”‚  - RAG       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Stack TecnolÃ³gico Actualizado

```python
# Core LangChain/LangGraph
langchain==0.1.0
langchain-openai==0.0.5
langchain-anthropic==0.0.5
langgraph==0.0.20
langsmith==0.0.77  # Para tracing y monitoring

# Vector stores para RAG
chromadb==0.4.22
faiss-cpu==1.7.4

# Integrations (ya las tenemos)
PyGithub==2.1.1
redis==5.0.1
fastapi==0.104.1
```

## ğŸ”§ Componentes Principales

### 1. State Definition (Shared State)

```python
from typing import TypedDict, Annotated, List
from langgraph.graph import StateGraph
from operator import add

class AgentState(TypedDict):
    """Estado compartido entre todos los agentes"""
    # Task info
    task_id: str
    task_description: str
    project_path: str
    
    # Linear
    linear_main_issue_id: str
    linear_team_id: str
    linear_sub_issues: dict  # agent_id -> issue_id
    
    # GitHub
    github_repo: str
    github_base_branch: str
    github_agent_branches: dict  # agent_id -> branch_name
    github_prs: List[str]  # URLs of created PRs
    
    # Agent outputs
    agent_results: Annotated[dict, add]  # Accumulate results
    
    # Dependencies
    completed_agents: Annotated[List[str], add]
    blocked_agents: List[str]
    
    # Metadata
    started_at: str
    messages: Annotated[List[str], add]  # Log messages
```

### 2. Agent as LangChain Tool Node

```python
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain_openai import ChatOpenAI
from langchain.tools import Tool
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder

class LangGraphAgent:
    """
    Agent implementado con LangChain que funciona como nodo en LangGraph
    """
    
    def __init__(self, agent_id: str, config: dict):
        self.agent_id = agent_id
        self.config = config
        
        # LLM
        self.llm = ChatOpenAI(
            model="gpt-4-turbo-preview",
            temperature=0.2
        )
        
        # Tools que el agente puede usar
        self.tools = self._create_tools()
        
        # Prompt especializado
        self.prompt = self._create_prompt()
        
        # Agent executor
        self.agent = create_openai_functions_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt
        )
        
        self.executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            verbose=True
        )
    
    def _create_tools(self) -> List[Tool]:
        """Crear tools especÃ­ficas del agente"""
        return [
            Tool(
                name="read_file",
                func=self._read_file,
                description="Read a file from the project"
            ),
            Tool(
                name="write_file",
                func=self._write_file,
                description="Write content to a file"
            ),
            Tool(
                name="search_rag",
                func=self._search_rag,
                description="Search RAG knowledge base for patterns"
            ),
            Tool(
                name="run_tests",
                func=self._run_tests,
                description="Run tests to validate implementation"
            )
        ]
    
    def _create_prompt(self) -> ChatPromptTemplate:
        """Crear prompt especializado"""
        return ChatPromptTemplate.from_messages([
            ("system", f"""You are {self.config['name']}, {self.config['role']}.

Specialization: {self.config['specialization']}
Experience: {self.config['experience']}

Your task is to implement solutions following best practices and patterns 
from your RAG knowledge base.

Always:
1. Search RAG for relevant patterns
2. Implement with high quality code
3. Include tests
4. Document your changes
"""),
            MessagesPlaceholder(variable_name="chat_history", optional=True),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
    
    async def execute(self, state: AgentState) -> AgentState:
        """
        Execute agent task - this is the node function in LangGraph
        """
        try:
            # Construir input desde el state
            input_text = f"""
Task: {state['task_description']}
Project: {state['project_path']}

Previous agent results:
{json.dumps(state.get('agent_results', {}), indent=2)}

Implement your part of the solution.
"""
            
            # Ejecutar agent
            result = await self.executor.ainvoke({
                "input": input_text
            })
            
            # Actualizar state
            state['agent_results'][self.agent_id] = result['output']
            state['completed_agents'].append(self.agent_id)
            state['messages'].append(f"âœ… {self.agent_id} completed")
            
            # Actualizar Linear
            if state.get('linear_sub_issues', {}).get(self.agent_id):
                await self._update_linear(
                    state['linear_sub_issues'][self.agent_id],
                    result['output']
                )
            
            # Push to GitHub
            if self._has_code_changes(result):
                pr_url = await self._push_to_github(state, result)
                state['github_prs'].append(pr_url)
            
            return state
            
        except Exception as e:
            state['messages'].append(f"âŒ {self.agent_id} failed: {e}")
            raise
    
    def _read_file(self, path: str) -> str:
        """Tool: read file"""
        with open(path, 'r') as f:
            return f.read()
    
    def _write_file(self, path: str, content: str) -> str:
        """Tool: write file"""
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, 'w') as f:
            f.write(content)
        return f"Written to {path}"
    
    def _search_rag(self, query: str) -> str:
        """Tool: search RAG knowledge"""
        # Implementar bÃºsqueda en RAG (vector store)
        return "RAG results..."
    
    def _run_tests(self, test_path: str) -> str:
        """Tool: run tests"""
        # Ejecutar tests
        return "Tests passed"
```

### 3. LangGraph Workflow Definition

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.sqlite import SqliteSaver

def create_multi_agent_graph() -> StateGraph:
    """
    Crear el grafo de agentes con LangGraph
    
    Flujo:
    1. Architect analiza y planifica
    2. Security revisa requisitos
    3. Backend + Frontend en paralelo
    4. QA tests
    5. Observer analiza
    """
    
    # Inicializar agentes
    architect = LangGraphAgent('agent-01-architect', config)
    security = LangGraphAgent('agent-05-security', config)
    backend = LangGraphAgent('agent-03-backend', config)
    frontend = LangGraphAgent('agent-02-frontend', config)
    qa = LangGraphAgent('agent-07-qa', config)
    observer = LangGraphAgent('agent-12-observer', config)
    
    # Crear grafo
    workflow = StateGraph(AgentState)
    
    # AÃ±adir nodos
    workflow.add_node("architect", architect.execute)
    workflow.add_node("security", security.execute)
    workflow.add_node("backend", backend.execute)
    workflow.add_node("frontend", frontend.execute)
    workflow.add_node("qa", qa.execute)
    workflow.add_node("observer", observer.execute)
    
    # Definir edges (flujo)
    workflow.set_entry_point("architect")
    
    workflow.add_edge("architect", "security")
    
    # Conditional edge: si security aprueba, continuar
    def should_continue_after_security(state: AgentState) -> str:
        if "security_approved" in state.get('agent_results', {}).get('agent-05-security', ''):
            return "parallel"
        return "architect"  # Volver a arquitecto si hay problemas
    
    workflow.add_conditional_edges(
        "security",
        should_continue_after_security,
        {
            "parallel": "backend",
            "architect": "architect"
        }
    )
    
    # Backend y Frontend en paralelo (LangGraph maneja esto automÃ¡ticamente)
    workflow.add_edge("backend", "qa")
    workflow.add_edge("frontend", "qa")
    
    # QA al final
    workflow.add_edge("qa", "observer")
    
    # Observer finaliza
    workflow.add_edge("observer", END)
    
    # Compilar con checkpointing
    memory = SqliteSaver.from_conn_string("checkpoints.db")
    graph = workflow.compile(checkpointer=memory)
    
    return graph


# Uso del grafo
async def execute_task(task_description: str, project_path: str):
    """Ejecutar tarea en el multi-agent graph"""
    
    # Crear grafo
    graph = create_multi_agent_graph()
    
    # Estado inicial
    initial_state: AgentState = {
        "task_id": str(uuid.uuid4()),
        "task_description": task_description,
        "project_path": project_path,
        "linear_main_issue_id": "",
        "linear_team_id": "TEAM-123",
        "linear_sub_issues": {},
        "github_repo": "owner/repo",
        "github_base_branch": "main",
        "github_agent_branches": {},
        "github_prs": [],
        "agent_results": {},
        "completed_agents": [],
        "blocked_agents": [],
        "started_at": datetime.now().isoformat(),
        "messages": []
    }
    
    # Ejecutar grafo
    config = {"configurable": {"thread_id": initial_state["task_id"]}}
    
    final_state = await graph.ainvoke(initial_state, config)
    
    return final_state
```

### 4. Advanced: Parallel Execution

```python
from langgraph.pregel import Channel

def create_parallel_workflow() -> StateGraph:
    """
    Workflow con ejecuciÃ³n paralela real de agentes
    """
    workflow = StateGraph(AgentState)
    
    # ... aÃ±adir nodos ...
    
    # Ejecutar backend y frontend en paralelo
    workflow.add_edge("security", "parallel_start")
    
    # Fan-out
    workflow.add_edge("parallel_start", "backend")
    workflow.add_edge("parallel_start", "frontend")
    
    # Fan-in: esperar ambos
    def wait_for_both(state: AgentState) -> str:
        completed = state.get('completed_agents', [])
        if 'agent-03-backend' in completed and 'agent-02-frontend' in completed:
            return "qa"
        return "wait"
    
    workflow.add_conditional_edges(
        "backend",
        wait_for_both,
        {"qa": "qa", "wait": "parallel_end"}
    )
    
    workflow.add_conditional_edges(
        "frontend",
        wait_for_both,
        {"qa": "qa", "wait": "parallel_end"}
    )
    
    return workflow.compile()
```

## ğŸ¯ Ventajas de esta Arquitectura

### 1. **Observabilidad Total**
```python
from langsmith import Client

# Cada ejecuciÃ³n se trackea automÃ¡ticamente
client = Client()
# Ver en LangSmith UI: latencia, tokens, costos, errores
```

### 2. **Checkpointing AutomÃ¡tico**
```python
# Si falla un agente, reanudar desde ahÃ­
graph = workflow.compile(checkpointer=SqliteSaver(...))

# Reanudar desde checkpoint
state = await graph.ainvoke(
    None,  # No initial state
    config={"configurable": {"thread_id": "task-123"}}
)
```

### 3. **Human-in-the-loop**
```python
from langgraph.prebuilt import create_react_agent

# Interrumpir para aprobaciÃ³n humana
workflow.add_node("human_approval", human_approval_node)

def human_approval_node(state: AgentState) -> AgentState:
    # Esperar aprobaciÃ³n antes de deploy
    approval = interrupt("Do you approve this PR?")
    if not approval:
        state['messages'].append("âŒ Human rejected")
        return state
    return state
```

### 4. **Testing Simplificado**
```python
# Test individual de agentes
agent = LangGraphAgent('test-agent', config)
result = await agent.execute(mock_state)

# Test del grafo completo
graph = create_multi_agent_graph()
final_state = await graph.ainvoke(test_state)
assert 'agent-02-frontend' in final_state['completed_agents']
```

## ğŸš€ Ventajas vs Redis Streams

| Feature | Redis Streams | LangGraph |
|---------|--------------|-----------|
| **State Management** | Manual | Built-in |
| **Checkpointing** | Custom | Automatic |
| **Observability** | Custom logging | LangSmith UI |
| **Parallel execution** | Manual coordination | Native support |
| **Conditional routing** | Complex logic | Simple decorators |
| **Testing** | Integration tests only | Unit + Integration |
| **Human-in-loop** | Complex | Built-in |
| **Cost tracking** | Manual | Automatic |

## ğŸ“Š Estructura de Proyecto Actualizada

```
multi-agents/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”œâ”€â”€ langgraph_agent.py      # Base agent con LangChain
â”‚   â”‚   â”œâ”€â”€ tools.py                 # Shared tools
â”‚   â”‚   â””â”€â”€ rag_store.py             # RAG vector store
â”‚   â”œâ”€â”€ agent_01_architect.py
â”‚   â”œâ”€â”€ agent_02_frontend.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ graphs/
â”‚   â”œâ”€â”€ workflows.py                 # Graph definitions
â”‚   â”œâ”€â”€ state.py                     # State schemas
â”‚   â””â”€â”€ conditions.py                # Conditional routing
â”œâ”€â”€ integrations/
â”‚   â”œâ”€â”€ linear/
â”‚   â”œâ”€â”€ github/
â”‚   â””â”€â”€ langsmith/                   # LangSmith tracking
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ api.py                       # FastAPI endpoints
â”‚   â””â”€â”€ executor.py                  # Graph executor
â””â”€â”€ tests/
    â”œâ”€â”€ test_agents.py
    â””â”€â”€ test_workflows.py
```

## ğŸ¯ PrÃ³ximo Paso

Â¿Quieres que implemente:
1. âœ… **Agente base con LangChain + tools**
2. âœ… **DefiniciÃ³n del grafo LangGraph completo**
3. âœ… **Ejemplo end-to-end funcionando**
4. âœ… **RAG con vector store (ChromaDB/FAISS)**
5. âœ… **Dashboard con LangSmith**

Todo esto es **mucho mÃ¡s simple y robusto** que la arquitectura manual con Redis!
